{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fac97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\raghu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from csv import QUOTE_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21496ab",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9809408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6728e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sst = pd.read_csv(\"SST-2/train.tsv\",delimiter=\"\\t\")\n",
    "df_sst.head(3)\n",
    "df_sst_c=pd.DataFrame(df_sst['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737341f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67344</th>\n",
       "      <td>a delightful comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67345</th>\n",
       "      <td>anguish , anger and frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67346</th>\n",
       "      <td>at achieving the modest , crowd-pleasing goals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>a patient viewer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67348</th>\n",
       "      <td>this new jangle of noise , mayhem and stupidit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0           hide new secretions from the parental units       0\n",
       "1                   contains no wit , only labored gags       0\n",
       "2      that loves its characters and communicates som...      1\n",
       "3      remains utterly satisfied to remain the same t...      0\n",
       "4      on the worst revenge-of-the-nerds clichés the ...      0\n",
       "...                                                  ...    ...\n",
       "67344                               a delightful comedy       1\n",
       "67345                   anguish , anger and frustration       0\n",
       "67346  at achieving the modest , crowd-pleasing goals...      1\n",
       "67347                                  a patient viewer       1\n",
       "67348  this new jangle of noise , mayhem and stupidit...      0\n",
       "\n",
       "[67349 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c140769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                           sentence  label\n",
      "0      53858  its and pieces of the hot chick are so hilarious       1\n",
      "1      32877   stillborn except as a harsh conceptual exercise       0\n",
      "2      61990  flat-out amusing , sometimes endearing and oft...      1\n",
      "3      42737  is about the people who live in them , who hav...      1\n",
      "4      49433           rarely easy , obvious or self-indulgent       1\n",
      "...      ...                                                ...    ...\n",
      "67344  50781                                       a real film       1\n",
      "67345  22851  to ponder how a whole segment of pop-music his...      0\n",
      "67346  25006  sand 's masculine persona , with its love of l...      1\n",
      "67347   6325                                     nutty cliches       0\n",
      "67348  18584                                           goodies       1\n",
      "\n",
      "[67349 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sst1 = df_sst.sample(frac=1).reset_index()\n",
    "print(df_sst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b4f3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=df_sst1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f08ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df=df_sst1[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002bcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd39fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df_sst1[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9644fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_label=train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37ccc62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 37461, 0: 29688}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(dist_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb15bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_label=len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bf50487",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob_1=dist_label[1]/tot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ff5e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob_0=dist_label[0]/tot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b601f6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior probablity of class 1 :  0.5578787472635482\n",
      "prior probablity of class 0 :  0.44212125273645175\n"
     ]
    }
   ],
   "source": [
    "print(\"prior probablity of class 1 : \",prior_prob_1)\n",
    "print(\"prior probablity of class 0 : \",prior_prob_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a8c27",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbea0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ecbb882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokenizer(sent):\n",
    "    tkns=word_tokenize(sent)\n",
    "    tkns = ['<s>'] + tkns + ['</s>']\n",
    "    return tkns\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2bb0814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line of train data tokanization\n",
      "['<s>', 'the', 'pacing', 'is', 'often', 'way', 'off', 'and', 'there', 'are', 'too', 'many', 'bona', 'fide', 'groaners', 'among', 'too', 'few', 'laughs', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"first line of train data tokanization\")\n",
    "print(convert_tokenizer(train_df.sentence[200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "144146a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent_train=[]\n",
    "for i in train_df.sentence:\n",
    "    all_sent_train.append(convert_tokenizer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "65d85089",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for sentence_tokens in all_sent_train for token in sentence_tokens]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e06ff49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14806"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad883f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e6d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "5f2e5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeni_dict={}\n",
    "for i in tokens:\n",
    "    if(i not in tokeni_dict.keys()):\n",
    "        tokeni_dict[i]=1\n",
    "    else:\n",
    "        tokeni_dict[i]=tokeni_dict[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "103675f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14806"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be02be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22144c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66643f78",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af1e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a91d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_frequencies(all_sent_train):\n",
    "    bc = {}  \n",
    "    \n",
    "    for s in all_sent_train:\n",
    "        for i in range(len(s) - 1):\n",
    "            wi = s[i] \n",
    "            wj=s[i + 1] \n",
    "            \n",
    "\n",
    "            if wi not in bc:\n",
    "                bc[wi] = {}\n",
    "\n",
    "            if wj not in bc[wi]:\n",
    "                bc[wi][wj] = 0\n",
    "\n",
    "            bc[wi][wj] += 1\n",
    "\n",
    "    return bc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4cc3035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = bigram_frequencies(all_sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "11e11f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_answer = bigram_counts.get(\"<s>\").get(\"the\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff796a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4456"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "459f7b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14805"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa18e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "025c33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d5a7b",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d0a02bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def smooth_neg_prob(wn,wn_pre,bc,alpha,voc):\n",
    "    try:\n",
    "        \n",
    "        cnt=bc.get(wn_pre).get(wn,0)\n",
    "    except:\n",
    "        cnt=0\n",
    "    sum_cnt=np.array(list(bigram_counts.get(wn_pre,0).values())).sum()\n",
    "    p=(cnt+alpha)/(sum_cnt+voc*alpha)\n",
    "\n",
    "    return -1*math.log(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1bd7f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.024899084055268"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"alpha 0.001\")\n",
    "smooth_neg_prob(\"award\",\"academy\",bigram_counts,0.001,len(bigram_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "244ce3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.172373816771201"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"alpha 0.5\")\n",
    "smooth_neg_prob(\"award\",\"academy\",bigram_counts,0.5,len(bigram_counts.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38205195",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "3146db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_neg_prob_sent(sent_prom,bc,alpha,voc):\n",
    "    tot_log_prob=0\n",
    "    tok_sent=nltk.word_tokenize(sent_prom)\n",
    "    for i in range(1,len(tok_sent)):\n",
    "        temp_log=smooth_neg_prob(tok_sent[i],tok_sent[i-1],bc,alpha,voc)\n",
    "        tot_log_prob=tot_log_prob-temp_log\n",
    "    return tot_log_prob\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "70103ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_prom_1=\"this was a really great movie but it was a little too long.\"\n",
    "sent_prom_2=\"long too little a was it but movie great really a was this.\"\n",
    "alpha1=0.5\n",
    "alpha2=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c385215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sentence 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-78.68998057967534"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"for sentence 1\")\n",
    "smooth_neg_prob_sent(sent_prom_1,bigram_counts,alpha1,len(bigram_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f96cb44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sentence 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-116.84105640459761"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"for sentence 2\")\n",
    "smooth_neg_prob_sent(sent_prom_2,bigram_counts,alpha2,len(bigram_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84af49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029d2d5a",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a5b2b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_snt=\"\"\n",
    "for i in list(validation_df.sentence):\n",
    "    validation_snt=validation_snt+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7a934bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.001 -3697.1190755623497\n",
      "alpha 0.01 -3911.427647317069\n",
      "alpha 0.1 -4534.357858886998\n"
     ]
    }
   ],
   "source": [
    "al1=[0.001,0.01,0.1]\n",
    "best_alpha={}\n",
    "\n",
    "for i in al1:\n",
    "    \n",
    "    log_ans=smooth_neg_prob_sent(validation_snt,bigram_counts,i,len(bigram_counts.keys()))\n",
    "    best_alpha[log_ans]=i\n",
    "    print(\"alpha\",i,log_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ea72176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best alpha value is 0.001 of -3697.1190755623497\n"
     ]
    }
   ],
   "source": [
    "print(\"the best alpha value is\",best_alpha[max(best_alpha.keys())],\"of\",max(best_alpha.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5024c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee2eb7c",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9bda6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1=train_df.loc[train_df.label==1]\n",
    "train_df_0=train_df.loc[train_df.label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "efe6b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent_train_p=[]\n",
    "for i in train_df_1.sentence:\n",
    "    all_sent_train_p.append(convert_tokenizer(i))\n",
    "    \n",
    "all_sent_train_n=[]\n",
    "\n",
    "for i in train_df_0.sentence:\n",
    "    all_sent_train_n.append(convert_tokenizer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8a35c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_p = [token for sentence_tokens in all_sent_train_p for token in sentence_tokens]\n",
    "tokens_n = [token for sentence_tokens in all_sent_train_n for token in sentence_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5739be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11524\n",
      "11240\n"
     ]
    }
   ],
   "source": [
    "print(len(set(tokens_p)))\n",
    "print(len(set(tokens_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ba4fe630",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts_p = bigram_frequencies(all_sent_train_p)\n",
    "bigram_counts_n = bigram_frequencies(all_sent_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6096058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pred=pd.DataFrame()\n",
    "prediction=np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "207cd27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raghu\\AppData\\Local\\Temp\\ipykernel_35744\\759525314.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['pred']=prediction\n"
     ]
    }
   ],
   "source": [
    "test_df['pred']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "57f1c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prior=len(bigram_counts_p)/(len(bigram_counts_p)+len(bigram_counts_n))\n",
    "n_prior=len(bigram_counts_n)/(len(bigram_counts_p)+len(bigram_counts_n))\n",
    "ans_pred=[]\n",
    "for i in range(0,len(test_df)):\n",
    "    l1=test_df[i:i+1]\n",
    "    temp_sent=list(l1['sentence'])[0]\n",
    "    ps=smooth_neg_prob_sent(temp_sent,bigram_counts_p,0.001,len(bigram_counts_p))\n",
    "    ns=smooth_neg_prob_sent(temp_sent,bigram_counts_n,0.001,len(bigram_counts_n))\n",
    "\n",
    "    final_p=ps-p_prior\n",
    "    final_n=ns-n_prior\n",
    "    if(final_p>final_n):\n",
    "        ans_pred.append(1)\n",
    "    else:\n",
    "        ans_pred.append(0)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713cb03",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "5edd24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(list(test_df.label), ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ecea2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is  0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"the accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "fb4898bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ba2e0fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision score is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the precision score is\")\n",
    "precision_score(list(test_df.label), ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ad21454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the recall score is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8928571428571429"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the recall score is\")\n",
    "recall_score(list(test_df.label), ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980d9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3706e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
